---
layout: post
title: 时间序列模型汇总
subtitle: 
date: 2018-12-20
author: Salome
header-img: img/post-bg-2015.jpg
catalog: true
tags:

   - time series
---

[TOC]

# 概况

工作中遇到了很多有关时间序列的问题，发现时间序列预测的性质和传统的机器学习方法还是有很大不同的。调研了一番，关于时间序列预测现在主要有三类方法

- 传统的统计学方法，包括线性模型ARIMA以及金融领域用的比较多的非线性模型门限模型。统计方法的优点是理论成熟，方法论清晰，缺点是易用性不高，涉及到大量的统计检验以及假设。
- 将时间序列预测转换为监督学习问题，用传统的回归方法去做。这个我想大部分人都比较熟悉了。这里的难点就是需要我们自己去构造样本特征，以及做大量的特征工程。
- 由于时序天然的依赖性，可以很好的用RNN及其变体建模，适合有大量的时间序列数据需要同时预测，比如你手上有淘宝几百万个sku的销量数据需要同时预测未来销量。

# 统计学方法

经典的方法如ARIMA是主要运用于单变量、同方差的线性模型。在异方差场合，Engle提出了自回归条件异方差模型（ARCH）模型，随后又有很多人在此基础上拓展成了一系列的广义自回归条件异方差模型。在多变量场合，Granger提出了协整理论，有了协整的概念，在多变量场合变量是平稳的不再是必须条件了。在非线性场合主要有门限自回归模型等等。

## 时间序列的预处理

预处理主要指的是平稳性和纯随机性检验。对于不同性质的时间序列我们要选择不同的模型。

### 平稳性

平稳又分为宽平稳和严平稳。宽平稳有两个重要性质

- 常数均值 $EX_t=\mu$ 
- 常数方差
- 常数协方差-自协方差函数和自相关系数只依赖于时间的平移长度而与时间的起止点无关

#### 时间序列为什么要满足平稳性？

首先，我们要明确当我们拿到了一个观测序列，每个点都是由那个时间步上的随机变量产生的一个样本点。而我们传统的通过样本推断总体性质，都是由N个随机变量，M个样本点。一般的，M越大N越小越好。而由于时间序列的数据结构的特殊性，在任意时刻都只能获得一个观测样本点。由于样本信息太少，如果没有其它辅助信息，通常这种数据结构是没有办法分析的。而序列平稳性概念可以解决这个问题。

#### 平稳性检验

有两种方法，一种是根据时序图和自相关图显示的特征的图检验法；一种是构造检验统计量进行假设检验（单位根检验）的方法。

因为平稳序列的均值和方差为常数，所以平稳序列的时序图会显示该序列始终在一个常数值附近随机波动，并且波动的范围有界。在自相关图中，平稳序列的自相关系数会很快衰减为0，也就是说平稳序列一般具有短期相关性。

以下为图示法以及假设检验的python代码：

```python
# -*- coding:utf-8 -*-
from statsmodels.tsa.stattools import adfuller
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# 移动平均图
def draw_trend(timeSeries, size):
    f = plt.figure(facecolor='white')
    # 对size个数据进行移动平均
    rol_mean = timeSeries.rolling(window=size).mean()
    # 对size个数据进行加权移动平均
    rol_weighted_mean = pd.ewma(timeSeries, span=size)

    timeSeries.plot(color='blue', label='Original')
    rolmean.plot(color='red', label='Rolling Mean')
    rol_weighted_mean.plot(color='black', label='Weighted Rolling Mean')
    plt.legend(loc='best')
    plt.title('Rolling Mean')
    plt.show()

def draw_ts(timeSeries):
    f = plt.figure(facecolor='white')
    timeSeries.plot(color='blue')
    plt.show()

'''
　　Unit Root Test
   The null hypothesis of the Augmented Dickey-Fuller is that there is a unit
   root, with the alternative that there is no unit root. That is to say the
   bigger the p-value the more reason we assert that there is a unit root
'''
def testStationarity(ts):
    dftest = adfuller(ts)
    # 对上述函数求得的值进行语义描述
    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])
    for key,value in dftest[4].items():
        dfoutput['Critical Value (%s)'%key] = value
    return dfoutput

# 自相关和偏相关图，默认阶数为31阶
def draw_acf_pacf(ts, lags=31):
    f = plt.figure(facecolor='white')
    ax1 = f.add_subplot(211)
    plot_acf(ts, lags=31, ax=ax1)
    ax2 = f.add_subplot(212)
    plot_pacf(ts, lags=31, ax=ax2)
    plt.show()
```

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gacqvov1nrj30ia0la0vg.jpg)

上图具有上升趋势和周期性，自相关图拖尾呈现长期相关性，明显是非平稳序列。

#### 纯随机性检验

序列平稳性检验之后，如是非平稳序列那么需要进一步的检验、变换之后才能确定合适的拟合模型。对于平稳序列来说，我们还要检验它的纯随机性。并不是所有的平稳序列都值得建模，只有那些序列值之间具有密切的相关关系，历史数据对未来的发展有一定影响的序列， 才值得花时间去挖掘历史数据中的有效信息。如果序列值之间完全没有相关性，这种序列称为纯随机性序列，是没有分析价值的。判断是否纯随机性，就是判断历史上间隔K期的序列值之间是否存在一定程度的相互影响关系。我们分析的目的就是把这种相关信息从序列值中提取出来。一般通过LB统计量进行假设检验判断序列是否纯随机。



## 平稳时间序列分析

ARMA模型是最常用的平稳序列拟合模型。

### AR模型

具有如下结构的模型称为P阶自回归模型，AR(P)
$$
x_t=\phi_0+\phi_1x_{t-1}+...+\phi_px_{t-p}+\epsilon_t
$$
随机干扰序列为0均值白噪声序列

AR模型是用来拟合平稳序列的，但是并不是所有的AR模型都是平稳的。判断平稳性有特征根判别和平稳阈判别。

###### 自相关系数的特性

平稳AR模型的自相关系数有两个显著的特质：一是拖尾性，而是呈指数衰减。

###### 偏自相关系数的特性

偏自相关系数是指去除两个变量中间的影响之后计算的相关系数。

平稳AR模型的偏自相关系数展现截尾性质

### MA模型

具有如下结构的模型称为q阶移动平均模型，MA(q)
$$
x_t=\mu+\epsilon_t-\theta_1\epsilon_{t-1}-...-\theta_q\epsilon_{t-q}
$$
随机干扰序列为0均值白噪声序列

###### 自相关系数的特性

平稳MA模型的自相关系数q阶截尾

###### 偏自相关系数的特性

平稳MA模型的偏自相关系数展现拖尾性质

### ARMA模型

具有如下结构的模型称为自回归移动平均模型，ARMA(p,q)
$$
x_t=\phi_0+\phi_1x_{t-1}+...+\phi_px_{t-p}+\epsilon_t-\theta_1\epsilon_{t-1}-...-\theta_q\epsilon_{t-q}
$$
随机干扰序列为0均值白噪声序列

###### 自相关系数的特性

拖尾

###### 偏自相关系数的特性

拖尾

### 平稳序列建模步骤

1. 根据样本的自相关系数和偏自相关系数定阶
2. 模型参数估计，一般用最大似然法或者最小二乘法。
3. 模型以及参数的显著性检验。模型显著性检验一般是检验残差项是否为白噪声序列（LB检验），参数检验主要是T统计量检验。
4. 模型优化，同一个序列可能可以构造两个模型，每个模型都显著有效。根据AIC以及SBC准则选择模型

- AIC准则 

AIC=-2ln(模型的极大似然函数值)+2(模型中未知参数个数)

AIC最小的模型是最优的模型

- SBC准则

SBC=-2ln(模型的极大似然函数值)+ln(n)(模型中未知参数个数)

## 非平稳序列的确定性分析

非平稳序列的分析方法有确定性分析以及随机性分析两类。

Cramer分解定理：任何一个时间序列都可以分解为两部分的叠加：其中一部分是由多项式决定的确定性成分，另一部分是零均值误差成分。ARMA是在拟合随机序列。

### 确定性因素分解

由确定性因素导致的非平稳，通常都有非常明显的规律，比如有固定的趋势和变化周期。最常用的确定性分析方法是确定性因素分解。

将序列的变化归纳为四大类因素的综合影响：

- 长期趋势
- 循环波动
- 季节性波动
- 随机波动

对这些因素进行组合有加法模型和乘法模型。

statsmodels使用的X-11分解过程，它主要将时序数据分离成长期趋势、季节趋势和随机成分。与其它统计软件一样，statsmodels也支持两类分解模型，加法模型和乘法模型，这里我只实现加法，乘法只需将model的参数设置为"multiplicative"即可。

```python
from statsmodels.tsa.seasonal import seasonal_decompose
decomposition = seasonal_decompose(ts_log, model="additive")

trend = decomposition.trend
seasonal = decomposition.seasonal
residual = decomposition.resid
```

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gacr7f8loyj30ie0cq0vf.jpg)

#### 趋势分析

##### 趋势拟合

分为线性拟合和曲线拟合

##### 平滑法

分为指数平滑法和移动平均法

#### 季节效应分析

$$
x_t=x*S_j+I_j
$$

$S_j$为季节指数，计算方法如下：

1. 计算周期内各期平均值
2. 计算总平均值
3. 用周期平均值除以总平均值

#### 综合分析

首先判断趋势和季节是否独立，如果独立用加法模型。否则乘法模型。如果用乘法模型，首先计算季节指数，用原始值除以季节指数消除掉季节影响之后再用线性拟合趋势。

## 非平稳序列的随机分析

非平稳序列的确定性分析原理简单，操作简单易于解释。但有如下问题：

1. 确定性分解只能提取强劲的确定性信息，对随机信息浪费。
2. 无法明确四大因素明确的相互作用关系

前面介绍过的季节指数等方法都是在提取确定性信息，然而都不够充分。差分运算的实质是使用自回归的方式提取确定性信息。1阶差分可以提取线性趋势，二阶查分可以提取曲线趋势，对序列进行周期阶查分可以提取周期信息。因此，差分可以提取序列中的趋势和周期信息，序列呈现典型的随机波动特征。

### 平稳性处理

#### 对数变换

```python
ts_log = np.log(ts)
test_stationarity.draw_ts(ts_log)
```

#### 平滑法

```python
test_stationarity.draw_trend(ts_log, 12)
```

#### 差分

statsmodel中，对差分的支持不是很好，它不支持高阶和多阶差分，最多支持二阶差分。所以需要我们将序列用pandas差分好，之后再还原。

```python
rol_mean = ts_log.rolling(window=12).mean()
rol_mean.dropna(inplace=True)
ts_diff_1 = rol_mean.diff(1)
ts_diff_1.dropna(inplace=True)
test_stationarity.testStationarity(ts_diff_1)
```

根据自相关和偏自相关图定阶。

```python
from statsmodels.tsa.arima_model import ARMA
model = ARMA(ts_diff_1, order=(1, 1)) 
result_arma = model.fit( disp=-1, method='css')
```

```python
predict_ts = result_arma.predict()
# 一阶差分还原
diff_shift_ts = ts_diff_1.shift(1)
diff_recover = predict_ts.add(diff_shift_ts)

# 移动平均还原
rol_sum = ts_log.rolling(window=11).sum()
rol_recover = diff_recover*12 - rol_sum.shift(1)
# 对数还原
log_recover = np.exp(rol_recover)
log_recover.dropna(inplace=True)
```

```python
ts = ts[log_recover.index]  # 过滤没有预测的记录
plt.figure(facecolor='white')
log_recover.plot(color='blue', label='Predict')
ts.plot(color='red', label='Original')
plt.legend(loc='best')
plt.title('RMSE: %.4f'% np.sqrt(sum((log_recover-ts)**2)/ts.size))
plt.show()
```

statsmodels里面的ARIMA模块不支持高阶差分，我们的做法是将差分分离出来，但是这样会多了一步人工还原的操作。基于上述问题，可以将差分过程进行了封装，使序列能按照指定的差分列表依次进行差分，并相应的构造了一个还原的方法，实现差分序列的自动还原。

```python
# 差分操作
def diff_ts(ts, d):
    global shift_ts_list
    #  动态预测第二日的值时所需要的差分序列
    global last_data_shift_list
    shift_ts_list = []
    last_data_shift_list = []
    tmp_ts = ts
    for i in d:
        last_data_shift_list.append(tmp_ts[-i])
        print last_data_shift_list
        shift_ts = tmp_ts.shift(i)
        shift_ts_list.append(shift_ts)
        tmp_ts = tmp_ts - shift_ts
    tmp_ts.dropna(inplace=True)
    return tmp_ts

# 还原操作
def predict_diff_recover(predict_value, d):
    if isinstance(predict_value, float):
        tmp_data = predict_value
        for i in range(len(d)):
            tmp_data = tmp_data + last_data_shift_list[-i-1]
    elif isinstance(predict_value, np.ndarray):
        tmp_data = predict_value[0]
        for i in range(len(d)):
            tmp_data = tmp_data + last_data_shift_list[-i-1]
    else:
        tmp_data = predict_value
        for i in range(len(d)):
            try:
                tmp_data = tmp_data.add(shift_ts_list[-i-1])
            except:
                raise ValueError('What you input is not pd.Series type!')
        tmp_data.dropna(inplace=True)
    return tmp_data
diffed_ts = diff_ts(ts_log, d=[12, 1])
model = arima_model(diffed_ts)
model.certain_model(1, 1)
predict_ts = model.properModel.predict()
diff_recover_ts = predict_diff_recover(predict_ts, d=[12, 1])
log_recover = np.exp(diff_recover_ts)
```

通过BIC准则自动寻找最优的阶数

```python
def proper_model(data_ts, maxLag):
    init_bic = sys.maxint
    init_p = 0
    init_q = 0
    init_properModel = None
    for p in np.arange(maxLag):
        for q in np.arange(maxLag):
            model = ARMA(data_ts, order=(p, q))
            try:
                results_ARMA = model.fit(disp=-1, method='css')
            except:
                continue
            bic = results_ARMA.bic
            if bic < init_bic:
                init_p = p
                init_q = q
                init_properModel = results_ARMA
                init_bic = bic
    return init_bic, init_p, init_q, init_properModel
```



### ARIMA

由于差分运算可以提取趋势和周期信息，许多非平稳的序列经过差分运算后后显示平稳序列的性质。ARIMA模型实质上就是差分运算和ARMA模型的结合。

#### 季节模型

ARIMA可以对具有季节效应的序列建模，可以分为简单季节模型和乘积季节模型。

##### 简单季节模型

周期和趋势以及随机项是加法模型，这时只要通过低阶差分去除趋势，周期阶差分去除周期趋势即可用ARMA建模

##### 乘积季节模型

ARIMA(p,d,q)X(P,D,Q)s

前面一部分为非季节性分量，后面为季节性分量，s为周期。

我们将使用一个名为“来自美国夏威夷Mauna Loa天文台的连续空气样本的大气二氧化碳”的数据集，该数据集从1958年3月至2001年12月期间收集了二氧化碳样本

```python
import warnings
import itertools
import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

data = sm.datasets.co2.load_pandas()
y = data.data

# 重采样
y = y['co2'].resample('MS').mean()
y = y.fillna(y.bfill())
print(y)
# 可视化 当我们绘制数据时，会出现一些可区分的模式。 时间序列具有明显的季节性格局，总体呈上升趋势。
y.plot(figsize=(15, 6))
plt.show()

# 使用网格搜索来迭代地搜索不同的超参数
p = d = q = range(0, 2)
pdq = list(itertools.product(p, d, q))
seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]

print('Examples of parameter combinations for Seasonal ARIMA...')
print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))
print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))
print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))
print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))


warnings.filterwarnings("ignore") # specify to ignore warning messages

for param in pdq:
    for param_seasonal in seasonal_pdq:
        try:
            mod = sm.tsa.statespace.SARIMAX(y,
                                            order=param,
                                            seasonal_order=param_seasonal,
                                            enforce_stationarity=False,
                                            enforce_invertibility=False)

            results = mod.fit()

            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))
        except:
            continue

# 拟合
mod = sm.tsa.statespace.SARIMAX(y,
                                order=(1, 1, 1),
                                seasonal_order=(1, 1, 1, 12),
                                enforce_stationarity=False,
                                enforce_invertibility=False)

results = mod.fit()

print(results.summary().tables[1])

# 检验
results.plot_diagnostics(figsize=(15, 12))
plt.show()

#预测
pred = results.get_prediction(start=pd.to_datetime('1998-01-01'), dynamic=False)
pred_ci = pred.conf_int()

#绘图
ax = y['1990':].plot(label='observed')
pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7)

ax.fill_between(pred_ci.index,
                pred_ci.iloc[:, 0],
                pred_ci.iloc[:, 1], color='k', alpha=.2)

ax.set_xlabel('Date')
ax.set_ylabel('CO2 Levels')
plt.legend()

plt.show()

# 使用RMSE判断
y_forecasted = pred.predicted_mean
y_truth = y['1998-01-01':]
mse = ((y_forecasted - y_truth) ** 2).mean()
print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))

# 生成未来的预测
pred_uc = results.get_forecast(steps=500)
pred_ci = pred_uc.conf_int()
ax = y.plot(label='observed', figsize=(20, 15))
pred_uc.predicted_mean.plot(ax=ax, label='Forecast')
ax.fill_between(pred_ci.index,
                pred_ci.iloc[:, 0],
                pred_ci.iloc[:, 1], color='k', alpha=.25)
ax.set_xlabel('Date')
ax.set_ylabel('CO2 Levels')

plt.legend()
plt.show()
```



#### 残差自回归

首先提取确定性因素，对剩下的随机项用自回归拟合。