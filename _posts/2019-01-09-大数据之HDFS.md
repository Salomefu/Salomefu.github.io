---
layout: post
title: 大数据之HDFS
subtitle: 
date: 2019-01-09
author: Salome
header-img: img/post-bg-2015.jpg
catalog: true
tags:

   - big data
---

# HDFS概述

HDFS是一个分布式的文件系统，用于存储文件，通过目录树来定位文件。HDFS的使用场景：适合一次写入多次写出的场景且不支持文件的修改，比较适合做数据分析但是不适合做网盘应用。  

##### 优点：  

1）高容错性

有多个副本提高容错性

2）可构建在廉价机器之上  

##### 缺点：  

1）不适合低延时数据访问

2）无法高效的对大量小文件进行存储

3）不支持并发写入，不支持文件的随机修改，只支持数据追加。

##### 架构

![HDFS](https://hadoop.apache.org/docs/r1.2.1/images/hdfsarchitecture.gif)



1）NameNode

是master node,负责管理数据块的映射信息；处理客户端读写请求；配置副本策略

2）DataNode

是slave node,负责执行数据块的读写操作，存储实际的数据块。

3）Client

- 文件切分，文件上传的时候，将文件切分成一个一个的block,然后进行上传。
- 与namenode交互，获取文件的位置信息；
- 与datanode交互，读取或者写入数据；

4）Secondary NameNode

定期合并Fsimage和Edits并推送给NameNode;

##### HDFS文件块大小

HDFS中的文件在物理上是分块（block）存储，快的大小通过配置参数来决定（dfs.bocksize），2.X中默认是128M；

寻址时间约为10ms,即查找到目标block的时间为10ms,一般来说寻址时间为传输时间的1%是最佳状态。因此传输时间=10ms/0.01=1000ms=1s,而目前磁盘的传输速率一般为100MB/s. 块太小会增加寻址时间，块太大磁盘传输数据时间明显大于定位这个块开始位置所需的时间。HDFS块的大小设置主要取决于磁盘传输速率。

# HDFS客户端操作

##### 基本语法

bin/hadoop fs 具体命令  OR  bin/hdfs dfs 具体命令

dfs是fs的实现类。

2．命令大全

```
[root@hadoop100 hadoop-2.7.2]$ bin/hadoop fs
```

3．常用命令实操

（0）启动Hadoop集群（方便后续的测试）

```
[root@hadoop100 hadoop-2.7.2]$ sbin/start-dfs.sh  
[root@hadoop101 hadoop-2.7.2]$ sbin/start-yarn.sh
```

（1）-help：输出这个命令参数

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -help rm
```

（2）-ls: 显示目录信息

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -ls /
```

（3）-mkdir：在HDFS上创建目录

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -mkdir -p /test/test1
```

（4）-moveFromLocal：从本地剪切粘贴到HDFS

```
[root@hadoop100 hadoop-2.7.2]$ touch testxt.txt  
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -moveFromLocal ./testxt.txt /test/test1
```

（5）-appendToFile：追加一个文件到已经存在的文件末尾

```
[root@hadoop100 hadoop-2.7.2]$ touch testxt2.txt  
[root@hadoop100 hadoop-2.7.2]$ vi testxt2.txt
```

输入

test the command

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -appendToFile testxt2.txt /test/test1/testxt.txt
```

（6）-cat：显示文件内容

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -cat /test/test1/testxt.txt
```

（7）-chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -chmod 666 /test/test1/testxt.txt

[root@hadoop100 hadoop-2.7.2]$ hadoop fs -chown root:root  /test/test1/testxt.txt
```

（8）-copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -copyFromLocal README.txt /
```

（9）-copyToLocal：从HDFS拷贝到本地

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -copyToLocal /test/test1/testxt.txt ./
```

（10）-cp ：从HDFS的一个路径拷贝到HDFS的另一个路径

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -cp /test/test1/testxt.txt /testxt3.txt
```

（11）-mv：在HDFS目录中移动文件

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -mv /testxt3.txt /test/test1/
```

（12）-get：等同于copyToLocal，就是从HDFS下载文件到本地

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -get /test/test1/testxt.txt ./
```

（13）-getmerge：合并下载多个文件，比如HDFS的目录 /user/root/test下有多个文件:log.1, log.2,log.3,...

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -getmerge /user/root/test/* ./zaiyiqi.txt
```

（14）-put：等同于copyFromLocal

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -put ./zaiyiqi.txt /user/root/test/
```

（15）-tail：显示一个文件的末尾

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -tail /test/test1/testxt.txt
```

（16）-rm：删除文件或文件夹

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -rm /user/root/test/jinlian.txt
```

（17）-rmdir：删除空目录

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -mkdir /test

[root@hadoop100 hadoop-2.7.2]$ hadoop fs -rmdir /test
```

（18）-du统计文件夹的大小信息

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -du -s -h /user/root/test  
2.7 K /user/root/test
```

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -du -h /user/root/test
```

（19）-setrep：设置HDFS中文件的副本数量

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -setrep 10 /test/test1/testxt.txt
```

这里设置的副本数只是记录在NameNode的元数据中，是否真的会有这么多副本，还得看DataNode的数量。因为目前只有3台设备，最多也就3个副本，只有节点数的增加到10台时，副本数才能达到10。

# HDFS的数据流

##### HDFS写数据流程

![](https://tva1.sinaimg.cn/large/006tNbRwly1ga6k02nds4j31kx0u0gum.jpg)

1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。

2）NameNode返回是否可以上传。

3）客户端请求第一个 Block上传到哪几个DataNode服务器上。

4）NameNode返回3个DataNode节点，分别为dn1、dn2、dn3。

5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。

6）dn1、dn2、dn3逐级应答客户端。

7）客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。

8）当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。

##### 网络拓扑-节点距离计算

在HDFS写数据的过程中，NameNode会选择距离待上传数据最近距离的DataNode接收数据。那么这个最近距离怎么计算呢？节点距离：两个节点到达最近的共同祖先的距离总和。

![](https://tva1.sinaimg.cn/large/006tNbRwly1ga6k0x08c9j31ky0u0dlm.jpg)

##### 副本存储节点选择

For the common case, when the replication factor is three, HDFS’s placement policy is to put one replica on one node in the local rack, another on a different node in the local rack, and the last on a different node in a different rack.

##### HDFS读数据流程

![](https://tva1.sinaimg.cn/large/006tNbRwly1ga6k17n8mxj31kw0u0jyj.jpg)



1）客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。

2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。

3）DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。

4）客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。

# NameNode和2NameNode

##### NN和2NN工作机制

思考：NameNode中的元数据是存储在哪里的？

首先，我们做个假设，如果存储在NameNode节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。因此，元数据需要存放在内存中。但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了。因此产生在磁盘中备份元数据的FsImage。

这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新FsImage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦NameNode节点断电，就会产生数据丢失。因此，引入Edits文件(只进行追加操作，效率很高)。每当元数据有更新或者添加元数据时，修改内存中的元数据并追加到Edits中。这样，一旦NameNode节点断电，可以通过FsImage和Edits的合并，合成元数据。

但是，如果长时间添加数据到Edits中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。因此，需要定期进行FsImage和Edits的合并，如果这个操作由NameNode节点完成，又会效率过低。因此，引入一个新的节点SecondaryNamenode，专门用于FsImage和Edits的合并。

![namenode](https://tva1.sinaimg.cn/large/006tNbRwly1ga6k45oep4j31j10u0am3.jpg)

1. 第一阶段：NameNode启动

（1）第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。

（2）客户端对元数据进行增删改的请求。

（3）NameNode记录操作日志，更新滚动日志。

（4）NameNode在内存中对元数据进行增删改。

2. 第二阶段：Secondary NameNode工作

​    （1）Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果。

​    （2）Secondary NameNode请求执行CheckPoint。

​    （3）NameNode滚动正在写的Edits日志。

​    （4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。

​    （5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并。

​    （6）生成新的镜像文件fsimage.chkpoint。

​    （7）拷贝fsimage.chkpoint到NameNode。

​    （8）NameNode将fsimage.chkpoint重新命名成fsimage。

##### Fsimage和Edits解析

（1）查看oiv和oev命令

```
[root@hadoop100 current]$ hdfs

**oiv**      apply the offline fsimage viewer to an fsimage

**oev**      apply the offline edits viewer to an edits file
```

（2）基本语法

hdfs oiv -p 文件类型 -i镜像文件 -o 转换后文件输出路径

（3）案例实操

```
[root@hadoop100 current]$ pwd

/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current

[root@hadoop100 current]$ hdfs oiv -p XML -i fsimage_0000000000000000025 -o /opt/module/hadoop-2.7.2/fsimage.xml
```

```
[root@hadoop100 current]$ cat /opt/module/hadoop-2.7.2/fsimage.xml
```

（1）基本语法

hdfs oev -p 文件类型 -i编辑日志 -o 转换后文件输出路径

（2）案例实操

```
[root@hadoop100 current]$ hdfs oev -p XML -i edits_0000000000000000012-0000000000000000013 -o /opt/module/hadoop-2.7.2/edits.xml

[root@hadoop100 current]$ cat /opt/module/hadoop-2.7.2/edits.xml
```

##### CheckPoint时间设置

（1）通常情况下，SecondaryNameNode每隔一小时执行一次。

```xml
[hdfs-default.xml]
<property>
 <name>dfs.namenode.checkpoint.period</name>
 <value>3600</value>
</property>
```

（2）一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次。

```xml
<property>
 <name>dfs.namenode.checkpoint.txns</name>
 <value>1000000</value>
<description>操作动作次数</description>
</property>
<property>
 <name>dfs.namenode.checkpoint.check.period</name>
 <value>60</value>
<description> 1分钟检查一次操作次数</description>
</property >
```



##### NameNode故障处理

使用-importCheckpoint选项启动NameNode守护进程，从而将SecondaryNameNode中数据拷贝到NameNode目录中。

1. 修改hdfs-site.xml中的

```xml
<property>
 <name>dfs.namenode.checkpoint.period</name>
 <value>120</value>
</property>
<property>
 <name>dfs.namenode.name.dir</name>
 <value>/opt/module/hadoop-2.7.2/data/tmp/dfs/name</value>
</property>
```

2. kill -9 NameNode进程

3. 删除NameNode存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）

```
[root@hadoop100 hadoop-2.7.2]$ rm -rf /opt/module/hadoop-2.7.2/data/tmp/dfs/name/*
```

4. 如果SecondaryNameNode不和NameNode在一个主机节点上，需要将SecondaryNameNode存储数据的目录拷贝到NameNode存储数据的平级目录，并删除in_use.lock文件

```
[root@hadoop100 dfs]$ scp -r root@hadoop102:/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary ./
[root@hadoop100 namesecondary]$ rm -rf in_use.lock
[root@hadoop100 dfs]$ pwd
/opt/module/hadoop-2.7.2/data/tmp/dfs
[root@hadoop100 dfs]$ ls
data name namesecondary
```

5. 导入检查点数据（等待一会ctrl+c结束掉）

```
[root@hadoop100 hadoop-2.7.2]$ bin/hdfs namenode -importCheckpoint
```

6. 启动NameNode

```
[root@hadoop100 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode
```

# DataNode



##### 工作机制

![](https://tva1.sinaimg.cn/large/006tNbRwly1ga6kwcy92aj31jx0u0the.jpg)

1）一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。

2）DataNode启动后向NameNode注册，通过后，周期性（1小时）的向NameNode上报所有的块信息。

3）心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。

4）集群运行中可以安全加入和退出一些机器。

##### 数据完整性

思考：如果电脑磁盘里面存储的数据是控制高铁信号灯的红灯信号（1）和绿灯信号（0），但是存储该数据的磁盘坏了，一直显示是绿灯，是否很危险？同理DataNode节点上的数据损坏了，却没有发现，是否也很危险，那么如何解决呢？

如下是DataNode节点保证数据完整性的方法。

1）当DataNode读取Block的时候，它会计算CheckSum。

2）如果计算后的CheckSum，与Block创建时值不一样，说明Block已经损坏。

3）Client读取其他DataNode上的Block。

##### 掉线时限参数设置

需要注意的是hdfs-site.xml 配置文件中的heartbeat.recheck.interval的单位为毫秒，dfs.heartbeat.interval的单位为秒。

```xml
<property>
  <name>dfs.namenode.heartbeat.recheck-interval</name>
  <value>300000</value>
</property>
<property>
  <name>dfs.heartbeat.interval</name>
  <value>3</value>
</property>
```

##### 服役新数据节点

0. 需求

随着公司业务的增长，数据量越来越大，原有的数据节点的容量已经不能满足存储数据的需求，需要在原有集群基础上动态添加新的数据节点。

1. 环境准备

​    （1）在hadoop102主机上再克隆一台hadoop103主机

​    （2）修改IP地址和主机名称

​    （3）删除原来HDFS文件系统留存的文件（/opt/module/hadoop-2.7.2/data和log）

​    （4）source一下配置文件

```
[root@hadoop103 hadoop-2.7.2]$ source /etc/profile
```

2. 服役新节点具体步骤

（1）直接启动DataNode，即可关联到集群

```
[root@hadoop103 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode
[root@hadoop103 hadoop-2.7.2]$ sbin/yarn-daemon.sh start nodemanager
```

（2）在hadoop103上传文件

```
[root@hadoop103 hadoop-2.7.2]$ hadoop fs -put /opt/module/hadoop-2.7.2/LICENSE.txt /
```

（3）如果数据不均衡，可以用命令实现集群的再平衡

```
[root@hadoop100 sbin]$ ./start-balancer.sh
starting balancer, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-balancer-hadoop100.out
Time Stamp        Iteration# Bytes Already Moved Bytes Left To Move Bytes Being Moved
```

##### 退役旧数据节点

- 添加白名单

​    添加到白名单的主机节点，都允许访问NameNode，不在白名单的主机节点，都会被退出。

配置白名单的具体步骤如下：

（1）在NameNode的/opt/module/hadoop-2.7.2/etc/hadoop目录下创建dfs.hosts文件

```
[root@hadoop100 hadoop]$ pwd

/opt/module/hadoop-2.7.2/etc/hadoop

[root@hadoop100 hadoop]$ touch dfs.hosts

[root@hadoop100 hadoop]$ vi dfs.hosts
```

添加如下主机名称（不添加hadoop103）

hadoop100

hadoop101

hadoop102

（2）在NameNode的hdfs-site.xml配置文件中增加dfs.hosts属性

```xml
<property>
<name>dfs.hosts</name>
<value>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts</value>
</property>
```

（3）配置文件分发

```
[root@hadoop100 hadoop]$ xsync hdfs-site.xml
```

（4）刷新NameNode

```
[root@hadoop100 hadoop-2.7.2]$ hdfs dfsadmin -refreshNodes  
Refresh nodes successful  
```

（5）更新ResourceManager节点

```
[root@hadoop100 hadoop-2.7.2]$ yarn rmadmin -refreshNodes  
```

（6） 如果数据不均衡，可以用命令实现集群的再平衡

```
[root@hadoop100 sbin]$ ./start-balancer.sh  
starting balancer, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-balancer-hadoop100.out  
Time Stamp        Iteration# Bytes Already Moved Bytes Left To Move Bytes Being Moved
```

##### 黑名单退役

在黑名单上面的主机都会被强制退出。

1. 在NameNode的/opt/module/hadoop-2.7.2/etc/hadoop目录下创建dfs.hosts.exclude文件

```
[root@hadoop100 hadoop]$ pwd

/opt/module/hadoop-2.7.2/etc/hadoop

[root@hadoop100 hadoop]$ touch dfs.hosts.exclude

[root@hadoop100 hadoop]$ vi dfs.hosts.exclude
```

添加如下主机名称（要退役的节点）

Hadoop103

2. 在NameNode的hdfs-site.xml配置文件中增加dfs.hosts.exclude属性

```xml
<property>

<name>dfs.hosts.exclude</name>

   <value>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude</value>

</property>
```

3．刷新NameNode、刷新ResourceManager

```
[root@hadoop100 hadoop-2.7.2]$ hdfs dfsadmin -refreshNodes  
Refresh nodes successful  
[root@hadoop100 hadoop-2.7.2]$ yarn rmadmin -refreshNodes  
```

4. 检查Web浏览器，退役节点的状态为decommission in progress（退役中），说明数据节点正在复制块到其他节点

5. 等待退役节点状态为decommissioned（所有块已经复制完成），停止该节点及节点资源管理器。注意：如果副本数是3，服役的节点小于等于3，是不能退役成功的，需要修改副本数后才能退役

```
[root@hadoop103 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop datanode  
stopping datanode
[root@hadoop103 hadoop-2.7.2]$ sbin/yarn-daemon.sh stop nodemanager
stopping nodemanager
```

6. 如果数据不均衡，可以用命令实现集群的再平衡

```
[root@hadoop100 hadoop-2.7.2]$ sbin/start-balancer.sh   
starting balancer, logging to /opt/module/hadoop-2.7.2/logs/hadoop-root-balancer-hadoop100.out
Time Stamp        Iteration# Bytes Already Moved Bytes Left To Move Bytes Being Moved
```

​    注意：不允许白名单和黑名单中同时出现同一个主机名称。



# HDFS 2.X新特性

##### 集群间数据拷贝

1．scp实现两个远程主机之间的文件复制

2．采用distcp命令实现两个Hadoop集群之间的递归数据复制

[root@hadoop100 hadoop-2.7.2]$ bin/hadoop distcp

hdfs://haoop100:9000/user/root/hello.txt hdfs://hadoop101:9000/user/root/hello.txt

##### 小文件存档       

（1）需要启动YARN进程

[root@hadoop100 hadoop-2.7.2]$ start-yarn.sh

（2）归档文件

​    把/user/root/input目录里面的所有文件归档成一个叫input.har的归档文件，并把归档后文件存储到/user/root/output路径下。

```
[root@hadoop100 hadoop-2.7.2]$ bin/hadoop archive -archiveName input.har –p /user/root/input  /user/root/output
```

（3）查看归档

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -lsr /user/root/output/input.har
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -lsr har:///user/root/output/input.har
```

（4）解归档文件

```
[root@hadoop100 hadoop-2.7.2]$ hadoop fs -cp har:/// user/root/output/input.har/*  /user/root
```

